{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frorozcoloa/FinancIA/blob/main/Notebooks/0-2%20Train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "epwoT-bYtT_E",
        "outputId": "c2eabe7a-ab0a-4666-8ef8-88f478ca8c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning\n",
            "  Downloading lightning-2.0.1.post0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Collecting starlette<2.0\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dateutils<2.0\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting croniter<1.4.0,>=1.3.0\n",
            "  Downloading croniter-1.3.14-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: Jinja2<5.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (3.1.2)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (4.11.2)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (13.3.3)\n",
            "Requirement already satisfied: urllib3<3.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (1.26.15)\n",
            "Collecting inquirer<5.0,>=2.10.0\n",
            "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.1.post0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting arrow<3.0,>=1.2.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (5.7.1)\n",
            "Requirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (1.5.1)\n",
            "Collecting uvicorn<2.0\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (1.10.7)\n",
            "Collecting deepdiff<8.0,>=5.7.0\n",
            "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting fastapi<0.89.0\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-cloud>=0.5.31\n",
            "  Downloading lightning_cloud-0.5.33-py3-none-any.whl (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.5/553.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec<2024.0,>=2022.5.0 in /usr/local/lib/python3.9/dist-packages (from lightning) (2023.4.0)\n",
            "Collecting websockets<12.0\n",
            "  Downloading websockets-11.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.9/dist-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from dateutils<2.0->lightning) (2022.7.1)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting starlette<2.0\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<2.0->lightning) (3.6.2)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting readchar>=3.0.6\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Collecting python-editor>=1.0.4\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting blessed>=1.19.0\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2<5.0->lightning) (2.1.2)\n",
            "Collecting pyjwt\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.1)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2024.0,>=2022.5.0->lightning) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<2.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.9/dist-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=706f8a8cf659e5286cc34a1f1dd5658543cbd94b33fdd5b19776a24237730661\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: tokenizers, python-editor, pathtools, websockets, smmap, setproctitle, sentry-sdk, readchar, python-multipart, pyjwt, ordered-set, multidict, lightning-utilities, h11, frozenlist, docker-pycreds, blessed, async-timeout, yarl, uvicorn, starlette, inquirer, huggingface-hub, gitdb, deepdiff, dateutils, croniter, arrow, aiosignal, transformers, starsessions, GitPython, fastapi, aiohttp, wandb, lightning-cloud, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 arrow-1.2.3 async-timeout-4.0.2 blessed-1.20.0 croniter-1.3.14 dateutils-0.6.12 deepdiff-6.3.0 docker-pycreds-0.4.0 fastapi-0.88.0 frozenlist-1.3.3 gitdb-4.0.10 h11-0.14.0 huggingface-hub-0.13.4 inquirer-3.1.3 lightning-2.0.1.post0 lightning-cloud-0.5.33 lightning-utilities-0.8.0 multidict-6.0.4 ordered-set-4.1.0 pathtools-0.1.2 pyjwt-2.6.0 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.1.post0 readchar-4.0.5 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 starlette-0.22.0 starsessions-1.3.0 tokenizers-0.13.3 torchmetrics-0.11.4 transformers-4.28.1 uvicorn-0.21.1 wandb-0.14.2 websockets-11.0.1 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers wandb torchmetrics lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import set_seed\n",
        "from torch import nn\n",
        "\n",
        "def SEED(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    set_seed(seed)\n",
        "\n",
        "\n",
        "SEED(42)\n",
        "\n",
        "\n",
        "# Configuration by model\n",
        "NUM_VARAIBLES = 3\n",
        "NUM_LABELS = 3\n",
        "num_labels = NUM_LABELS * NUM_VARAIBLES\n",
        "model_name = \"pysentimiento/roberta-es-sentiment\"\n",
        "\n",
        "divice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "HH7wdTX7tX8p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0eDkRBbStT_H",
        "outputId": "ee83ca5b-2c85-4dc3-bbc9-52551a239ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f09287a68f7f493dbb8ab224a1d0fdf0",
            "e3dcd0cc13354238a683c77a77f6c482",
            "bc3f87a41c2e462f81f24647bde2de55",
            "54aaecdbb36a4a9493c0a9095fc81946",
            "a8db70f8852f4aee98fd6232ec29915b"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f09287a68f7f493dbb8ab224a1d0fdf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3dcd0cc13354238a683c77a77f6c482",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc3f87a41c2e462f81f24647bde2de55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54aaecdbb36a4a9493c0a9095fc81946",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/925 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8db70f8852f4aee98fd6232ec29915b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis and are newly initialized because the shapes did not match:\n",
            "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
            "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import ( \n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_constant_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "# Configuring the model\n",
        "num_labels = NUM_LABELS * NUM_VARAIBLES\n",
        "# model_name = \"pysentimiento/roberta-es-sentiment\"\n",
        "model_name = \"pysentimiento/robertuito-sentiment-analysis\"\n",
        "auto_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FinanciaSentimental(Dataset):\n",
        "    \"\"\"This class is used to load the data and tokenize it\"\"\"\n",
        "    def __init__(self, tokenizer, dataframe, type):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.dataframe = dataframe\n",
        "        ## Columns to target\n",
        "        self._columns = [\"target_sentiment\", \"companies_sentiment\", \"consumers_sentiment\"]\n",
        "    \n",
        "    @property\n",
        "    def columns(self):\n",
        "        \"\"\"Return the columns to target\"\"\"\n",
        "        return self._columns\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the length of the dataset\"\"\"\n",
        "        return self.dataframe.count()\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get the data at the index\"\"\"\n",
        "        values = self.dataframe.iloc[index]\n",
        "        text = values['text']\n",
        "        label = pd.get_dummies(values[self._columns], columns=[self._columns]).values.astype(np.int8)\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        label = torch.tensor(label, dtype=torch.int8)\n",
        "        return inputs['input_ids'].squeeze(0), inputs['attention_mask'].squeeze(0)"
      ],
      "metadata": {
        "id": "Lhl4Jh_1HT54"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fOD5WnybtT_I"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy, F1Score, Precision, Recall\n",
        "import lightning.pytorch as pl\n",
        "\n",
        "class FinanciaMultilabel(pl.LightningModule):\n",
        "    \"\"\"This class is used to create the model\"\"\"\n",
        "    def __init__(self, num_labels, model_name, class_weights):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "        # The models is multi-label, so we need to use BCEWithLogitsLoss\n",
        "        self.loss = nn.BCEWithLogitsLoss(pos_weight=class_weights, reduction='none')\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=self.num_labels, ignore_mismatched_sizes=True)\n",
        "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        #Metrics for the model for training\n",
        "        self.train_f1 = F1Score(task = \"multilabel\", num_classes=self.num_labels)\n",
        "        self.train_accuracy = Accuracy(task =\"multilabel\", num_classes=self.num_labels)\n",
        "        self.train_precision = Precision(task =\"multilabel\", num_classes=self.num_labels)\n",
        "        self.train_recall = Recall(task =\"multilabel\", num_classes=self.num_labels)\n",
        "        # Metrics for the model for validation\n",
        "        self.val_f1 = F1Score(task = \"multilabel\", num_classes=self.num_labels)\n",
        "        self.val_accuracy = Accuracy(task =\"multilabel\", num_classes=self.num_labels)\n",
        "        self.val_precision = Precision(task =\"multilabel\", num_classes=self.num_labels)\n",
        "        self.val_recall = Recall(task =\"multilabel\", num_classes=self.num_labels)\n",
        "        \n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"This function is used to forward the data through the model\"\"\"\n",
        "        output = self.model(input_ids, attention_mask=attention_mask)\n",
        "        logits = output.logits\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"This function is used to train the model\"\"\"\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        logits = self(input_ids, attention_mask)\n",
        "        train_loss = self.loss(logits, labels)\n",
        "        train_acc = self.train_accuracy(logits, labels)\n",
        "        train_f1 = self.train_f1(logits, labels)\n",
        "        train_score = self.train_precision(logits, labels)\n",
        "        train_recall = self.train_recall(logits, labels)\n",
        "        self.log(\"train/loss\", train_loss, on_step=False, on_epoch=True)\n",
        "        self.log(\"train/accuracy\", self.train_accuracy, on_step=False, on_epoch=True)\n",
        "        self.log(\"train/precision\", self.train_precision, on_step=False, on_epoch=True)\n",
        "        self.log(\"train/recall\", self.train_recall, on_step=False, on_epoch=True)\n",
        "        self.log(\"train/f1_score\", self.train_f1_score, on_step=False, on_epoch=True)\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"This function is used to validate the model\"\"\"\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        logits = self(input_ids, attention_mask)\n",
        "        val_loss = self.loss(logits, labels)\n",
        "        val_acc = self.val_accuracy(logits, labels)\n",
        "        val_f1 = self.val_f1(logits, labels)\n",
        "        val_recall = self.val_recall(logits, labels)\n",
        "        val_precision = self.val_precision(logits, labels)\n",
        "        \n",
        "        self.log(\"val/loss\", val_loss, on_step=False, on_epoch=True)\n",
        "        self.log(\"val/accuracy\", self.val_accuracy, on_step=False, on_epoch=True)\n",
        "        self.log(\"val/precision\", self.val_precision, on_step=False, on_epoch=True)\n",
        "        self.log(\"val/recall\", self.val_recall, on_step=False, on_epoch=True)\n",
        "        self.log(\"val/f1_score\", self.val_f1_score, on_step=False, on_epoch=True)\n",
        "        self.log(\"val/loss\", val_loss, on_step=False, on_epoch=True)\n",
        "        return val_loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"This function is used to configure the optimizer\"\"\"\n",
        "        optimizer = torch.optim.AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mm0B6GdXKnqt",
        "outputId": "3bfd55e9-a11d-4752-e61a-a6324a3e7495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = \"/content/drive/Shareddrives/Redes neuronales/Datasets/train.csv\"\n",
        "df = pd.read_csv(train_df)\n",
        "train, test = train_test_split(df, test_split=0.20)\n",
        "valid, test = train_test_split(test, test_split=0.5)"
      ],
      "metadata": {
        "id": "_KZEVfRKJ_ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UreLqvPsKY0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FinanciaMultilabel(model_name num_classes=9)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "train_data = IMDBDataset(tokenizer, train_texts, train_labels)\n",
        "val_data = IMDBDataset(tokenizer, val_texts, val_labels)\n",
        "test_data = IMDBDataset(tokenizer, test_texts, test_labels)\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=8)\n",
        "test_loader = DataLoader(test_data, batch_size=8)\n",
        "wandb.init(project='my-project-name', config={\n",
        "    'batch_size': 8,\n",
        "    'learning_rate': 2e-5\n",
        "})\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=10)\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "trainer.test(model, test_loader)\n",
        "wandb.log({'test_loss': trainer.callback_metrics['test_loss'].item()})"
      ],
      "metadata": {
        "id": "-SWP1ooSG-56"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}